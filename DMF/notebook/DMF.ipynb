{"cells":[{"cell_type":"code","source":["\"\"\"\nAuthor: Santiago Morante\nDISTRIBUTED ANOMALY DETECTION ALGORITHM BASED ON DISSIMILARITY MAPPING FILTERING\nS. Morante, J. G. Victores and C. Balaguer, \"Automatic demonstration and feature selection for robot learning,\" \nHumanoid Robots (Humanoids), 2015 IEEE-RAS 15th International Conference on, Seoul, 2015, pp. 428-433.\ndoi: 10.1109/HUMANOIDS.2015.7363569\nURL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7363569&isnumber=7362951\n\"\"\"\n\nfrom pyspark.sql import DataFrame as DFPyspark\nfrom pyspark.sql import SQLContext\nfrom pyspark.rdd import RDD\nfrom pyspark import SparkContext\nfrom pandas import DataFrame as DFPandas\nfrom numpy.linalg import norm\nfrom fastdtw import fastdtw\n\nclass Signal():\n  \"\"\"\n  Signal:\n  1. Takes data in regular table style (rows, columns), \n  2. Converts it to RDD (if not yet)\n  3. Indexes every row with the index in the first position of a tupla (index, listOfValuesOfTheRow),\n  4. Imputes values in missing positions. --toDo\n  \n  Each tupla in a Signal instance represents a vector of data.\n  \"\"\"\n\n  def create(self, dataset):\n    \"\"\"Creates Signal from list, rdd, dataframe (spark) or dataframe (pandas)\"\"\"\n    rdd = self.convertToRDD(dataset)\n    return self.indexRDD(rdd)\n    \n  def convertToRDD(self, dataset):\n    \"\"\"Converts dataset into RDD (if not yet)\"\"\"\n    sc = SparkContext.getOrCreate()\n    if isinstance(dataset, RDD):\n      return dataset\n    elif isinstance(dataset, DFPyspark):\n        return dataset.rdd.map(list)\n    elif isinstance(dataset, DFPandas):\n      sqlContext = SQLContext.getOrCreate(sc)\n      return sqlContext.createDataFrame(dataset).rdd.map(list)\n    else:\n      try:\n          return sc.parallelize(dataset)\n      except TypeError:\n          print(\"convertToRDD cannot convert dataset because it is not one of the allowed types \\\n          (RDD, dataframe (sparkSQL) or dataframe (pandas))\")\n  \n  def indexRDD(self, rdd):\n    \"\"\"Index each row of a RDD as a tuple (index, listOfValuesOfTheRow)\"\"\"\n    return rdd.zipWithIndex().map(lambda x: (x[1],x[0]))\n  \n#######################################################################  \n\nclass DMF():\n    \"\"\"\n    DISSIMILARITY MAPPING FILTERING:\n    S. Morante, J. G. Victores and C. Balaguer, \"Automatic demonstration and feature selection for robot learning,\" \n    Humanoid Robots (Humanoids), 2015 IEEE-RAS 15th International Conference on, Seoul, 2015, pp. 428-433.\n    \n    :param data:                 RDD of data points\n    :param dissimilarityMethod:  Method for performing dissimilarity\n    :param mappingMethod:        Method for performing mapping\n    :param filteringMethod:      Method for performing filtering\n    :param theta:                Threhold used in filtering step\n    \"\"\"\n   \n    def __init__(self, dissimilarityMethod=\"euclidean\", mappingMethod=\"sum\", filteringMethod=\"zscore\", theta=0):\n      \"\"\"Initialize parameters\"\"\"\n      self.dissimilarityMethod = dissimilarityMethod\n      self.mappingMethod = mappingMethod\n      self.filteringMethod = filteringMethod\n      self.theta = theta\n\n    def dissimilarity(self, doublePairs): \n      \"\"\"DISSIMILARITY: calculate distance between elements\"\"\"\n      #euclidean\n      if self.dissimilarityMethod == \"euclidean\":\n        #convert to float\n        element0 = [float(x) for x in doublePairs[0][1]]\n        element1 = [float(x) for x in doublePairs[1][1]]\n        #subtract lists\n        subtraction = [a - b for a, b in zip(element1, element0)]\n        return float(doublePairs[0][0]), norm(subtraction)\n      #dtw\n      if self.dissimilarityMethod == \"dtw\":\n        #convert to float\n        element0 = [float(x) for x in doublePairs[0][1]]\n        element1 = [float(x) for x in doublePairs[1][1]]\n        #fastdtw\n        distance, path = fastdtw(element0, element1)\n        return float(doublePairs[0][0]), distance\n      #unknown\n      else:\n        raise ValueError(\"dissimilarityMethod should be an allowed method, \"\n                            \"but got %s.\" % str(dissimilarityMethod))\n\n    def mapping(self, a,b):\n      \"\"\"MAPPING: reduce the comparisons matrix to single value per element key\"\"\"\n      if self.mappingMethod == \"sum\":\n        return a+b\n      else:\n        raise ValueError(\"mappingMethod should be an allowed method, \"\n                              \"but got %s.\" % str(mappingMethod))\n        \n    def filtering(self, pairs, meanData, stdevData, theta):\n      \"\"\"FILTERING: filtering data by threshold (theta) using Z-score\"\"\"\n      if self.filteringMethod == \"zscore\":\n        try:\n          return (pairs[1] - meanData)/float(stdevData) > theta \n        except:\n          raise ValueError(\"Filtering Z-score division by zero (StDev=0)!  (all values are equal)\")\n      else:\n         raise ValueError(\"filteringMethod should be an allowed method, \"\n                              \"but got %s.\" % str(filteringMethod))\n\n    def detect(self, signals):\n      \"\"\"Detects anomalies in the dataset (must be in format (index,listOfValues))\"\"\"\n      #dissimilarity\n      dataDissimilarity = signals.cartesian(signals).map(self.dissimilarity)\n      #mapping\n      dataMapping = dataDissimilarity.reduceByKey(self.mapping)\n      #filtering\n      meanData= dataMapping.values().mean()\n      stdevData= dataMapping.values().stdev()\n      dataFiltering = dataMapping.filter(lambda pairs: self.filtering(pairs, meanData, stdevData, self.theta))\n      return dataFiltering"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#######################################################\n### MAIN ##############################################\n#######################################################\n\nfrom numpy import sin, linspace\nimport matplotlib.pylab as plt\nfrom pyspark import SparkContext\n\n#sparkContext\nsc = SparkContext.getOrCreate()\nsqlContext = SQLContext.getOrCreate(sc)\ndata=sqlContext.read.table(\"dim2small\")\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#create model\nmodel= DMF(dissimilarityMethod=\"dtw\")\nsignals = Signal().create(data)\n\n#detect using model\nprint (\"Index, totalValue: \", model.detect(signals).collect())"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":4}],"metadata":{"name":"DMF","notebookId":1029771884125740},"nbformat":4,"nbformat_minor":0}
